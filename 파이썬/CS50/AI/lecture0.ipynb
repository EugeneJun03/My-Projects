{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture 0 : Artificial Intelligence\n",
    "\n",
    "1. Search --- now\n",
    "2. Knowledge\n",
    "3. Uncertainty\n",
    "4. Optimization\n",
    "5. Learning\n",
    "6. Neural Networks\n",
    "7. Language"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Problem\n",
    "- map, maze, number problem\n",
    "\n",
    "## some basic knowledge\n",
    "- agent: entity that preceives its environment and acts upon that environment\n",
    "\n",
    "- state(s): a configuration of the agent and its environment\n",
    "\n",
    "- initial state: the begining state of agent\n",
    "\n",
    "- actions(a): choices that can be made in a state\n",
    "\n",
    "- transition model(resoult function{s,a}): a discription of what state results from performing any applicable action in any state\n",
    "\n",
    "#### \"Result{s,a} ==> new state\"\n",
    "\n",
    "- state space: the set of all states reachable from the initial state by any sequence of actions-can represent like a diagram, graphs\n",
    "\n",
    "- goal test: way to determine whether a given state is a goal state\n",
    "\n",
    "- path cost: numerical cost associated with a given path(which you should minimize)\n",
    "\n",
    "- optimal solution: a solution that has the lowest path cost among all solutions\n",
    "\n",
    "- node: a data structure that keeps track of \n",
    "    1. a state\n",
    "    2. a parent(node that generated this node)\n",
    "    3. an action(action applide to parent to get node)\n",
    "    4. a path cost(from initial state to node)\n",
    "\n",
    "## Approach\n",
    "1. Start with a frontier that contains the initial state\n",
    "2. Repeat:\n",
    "    - if the frontier is emplty -> no solution\n",
    "    - remove a node from the frontier\n",
    "    - if node contains goal state -> return the solution\n",
    "    - expand node, add resulting nodes to the frontier\n",
    "\n",
    "## Revised Approach\n",
    "1. Start with a frontier that contains the inital siate.\n",
    "2. Start with an empty explored set.\n",
    "3. Repeat:\n",
    "    - if ther frontier is empty -> no solution\n",
    "    - remove a node from the frontier\n",
    "    - if node contains goal state -> return the solution\n",
    "    - add the node to the explored set\n",
    "    - expand node, add resulting nodes to the frontier if they aren't already in the frontier or the explored set\n",
    "\n",
    "- stac: last-in first-out data type\n",
    "- queue: first-in first-out data type\n",
    "\n",
    "- depth-first search: search algorithm that always expands the deepest node in the frontier(use stac)  \n",
    "DFS is not going to garenty the best solution.\n",
    "\n",
    "- breadth-first search: search algorithm that always expands the shallowest node in the frontier(use queue)  \n",
    "BFS can find the best solution but it could be time consuming.\n",
    "\n",
    "- DFS and BFS both has a problem that they can taking the longest possible time before reaching the solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFS\n",
    "def remove(self):\n",
    "        # Terminate the search if the frontier is empty, because this means that there is no solution.\n",
    "    if self.empty():\n",
    "        raise Exception(\"empty frontier\")\n",
    "    else:\n",
    "            # Save the last item in the list (which is the newest node added)\n",
    "        node = self.frontier[-1]\n",
    "        # Save all the items on the list besides the last node (i.e. removing the last node)\n",
    "        self.frontier = self.frontier[:-1]\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFS\n",
    "def remove(self):\n",
    "        # Terminate the search if the frontier is empty, because this means that there is no solution.\n",
    "    if self.empty():\n",
    "        raise Exception(\"empty frontier\")\n",
    "    else:\n",
    "        # Save the oldest item on the list (which was the first one to be added)\n",
    "        node = self.frontier[0]\n",
    "        # Save all the items on the list besides the first one (i.e. removing the first node)\n",
    "        self.frontier = self.frontier[1:]\n",
    "        return node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed Search\n",
    "- search strategy that uses problem-spedific knowledge to find solutions more efficiently\n",
    "\n",
    "#### Greedy Best-First Search\n",
    "- search algorithm that expands the node that is closest to the goal, as estimated by a heuristic function = h(n)\n",
    "- ex)manhattan distance\n",
    "\n",
    "#### A* Search\n",
    "- search algorithm that expands node with lowest value of g(n)+h(n)\n",
    "    - g(n) = cost to reach node\n",
    "    - h(n) = estimated cost to goal\n",
    "But! do not trust without estimating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Search\n",
    "\n",
    "- like a game which has an opponent(tiktacto)\n",
    "- has win, lose and drow(1, -1, 0)\n",
    "\n",
    "### Minimax algorithm\n",
    "- Max: aims to maximize the score  \n",
    "\n",
    "- Min: aims to minimize the score  \n",
    "\n",
    "function\n",
    "\n",
    "#### Game \n",
    "- S0: initial state\n",
    "- Player(s): returns which player to move in state 's'\n",
    "- Actions(s): returns legal moves in state 's'\n",
    "- Result(s, a): returns state after action 'a' taken in the state 's'\n",
    "- Terminal(s): checks if state 's' is a terminal state\n",
    "    - false\n",
    "    - true\n",
    "- Utility(s): final numerical value for terminal state 's'\n",
    "    - \"1\": win\n",
    "    - \"-1\": lose\n",
    "    - \"0\": drow\n",
    "- Max/Min-Value(Result(s, a)): it calulate the value of the state\n",
    "    - Max picks action a in Actions(s) that produces highest value of Min-Value(Result(s, a))\n",
    "    - Min picks action a in Actions(s) that produces smallest value of Max-Value(Result(s, a))  \n",
    "\n",
    "#### Functions of Minimax\n",
    "- function Max-Value(s):  \n",
    "    - if Terminal(s):  \n",
    "        - return Utility(s)  \n",
    "    - v = -infinity  \n",
    "    - for action in Actions(s):  \n",
    "        - v = Max(v, Min-Value(Result(s, a)))\n",
    "    - return v\n",
    "\n",
    "- function Min-Value(s):  \n",
    "    - if Terminal(s):  \n",
    "        - return Utility(s)  \n",
    "    - v = +infinity  \n",
    "    - for action in Actions(s):  \n",
    "        - v = Min(v, Max-Value(Result(s, a)))\n",
    "    - return v\n",
    "\n",
    "### Optimizations\n",
    "- you don't need to do searching process if you are confident that you have a better solutions\n",
    "- \"Alpha-Beta Pruning\"\n",
    "\n",
    "### Depth-limited Minimax\n",
    "- it stops when reachs some amount of time\n",
    "- \"evaluation function\": function that extimates the expected utility of the game from a given state(this function determins the value of AI)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
